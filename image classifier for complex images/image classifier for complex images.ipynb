{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier for a set of happy or sad images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_happy_sad_model function\n",
    "def train_happy_sad_model():\n",
    "    DESIRED_ACCURACY = 0.999\n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            # if logs.get('acc') is not None and logs.get('acc') > DESIRED_ACCURACY:\n",
    "            if(logs.get('accuracy')>DESIRED_ACCURACY):\n",
    "                print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "    callbacks = myCallback()\n",
    "    \n",
    "    # Define and Compile the Model.assuming the images are 150 X 150 in the implementation.\n",
    "    model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                optimizer=RMSprop(learning_rate=0.001),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "    # creating an instance of an ImageDataGenerator called train_datagen \n",
    "    # And a train_generator by calling train_datagen.flow_from_directory\n",
    "    train_datagen = ImageDataGenerator(rescale=1/255) \n",
    "    train_generator = train_datagen.flow_from_directory( \"./happy-or-sad/\", \n",
    "                                                        target_size=(150, 150), \n",
    "                                                        batch_size=10, \n",
    "                                                        class_mode='binary') \n",
    "\n",
    "    # model fitting\n",
    "    history = model.fit(train_generator, \n",
    "                        steps_per_epoch=8, \n",
    "                        epochs=15, \n",
    "                        verbose=1, \n",
    "                        callbacks=[callbacks] \n",
    "                       )\n",
    "    \n",
    "    return history.history['accuracy'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 80 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 3.2418 - accuracy: 0.5333WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0594s vs `on_train_batch_end` time: 0.1264s). Check your callbacks.\n",
      "8/8 [==============================] - 3s 183ms/step - loss: 2.5650 - accuracy: 0.6000\n",
      "Epoch 2/15\n",
      "8/8 [==============================] - 1s 157ms/step - loss: 0.4987 - accuracy: 0.8125\n",
      "Epoch 3/15\n",
      "8/8 [==============================] - 1s 101ms/step - loss: 0.2715 - accuracy: 0.8750\n",
      "Epoch 4/15\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.2646 - accuracy: 0.9125\n",
      "Epoch 5/15\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.1223 - accuracy: 0.9625\n",
      "Epoch 6/15\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.1273 - accuracy: 0.9625\n",
      "Epoch 7/15\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.2240 - accuracy: 0.9000\n",
      "Epoch 8/15\n",
      "8/8 [==============================] - 0s 35ms/step - loss: 0.1157 - accuracy: 0.9375\n",
      "Epoch 9/15\n",
      "8/8 [==============================] - 0s 34ms/step - loss: 0.0313 - accuracy: 0.9875\n",
      "Epoch 10/15\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "\n",
      "Reached 99.9% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_happy_sad_model()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "461e704e5efbef18cb4dce531337118e0795ff295c21c4fa420395b880df1ac0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
